{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda, concatenate, multiply, Conv2D, Flatten, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder():\n",
    "    \n",
    "    def __init__(self, latent_dim = 5):\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    \n",
    "    def _sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "\n",
    "        epsilon = K.random_normal(shape =(batch, dim), mean=0.0, stddev=1.0)\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    \n",
    "    def _variational_autoencoder(self, orignal_dim):\n",
    "        \n",
    "        orignal_dim = int(orignal_dim[0])\n",
    "        inputs = Input(shape= orignal_dim, name = 'encoder_input')\n",
    "        x = Dense(64, activation = 'relu', kernel_initializer= 'he_uniform')(inputs)\n",
    "        x = Dense(128, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(64, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(32, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(30, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "\n",
    "        x = Dense(self.latent_dim, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        z_mean = Dense(self.latent_dim, activation = None, name='z_mean')(x)\n",
    "        z_log_var = Dense(self.latent_dim, activation = None, name='z_log_var'\n",
    "                          ,kernel_initializer = initializers.glorot_normal())(x)\n",
    "        z = Lambda(self._sampling, output_shape = (self.latent_dim,), name ='z')([z_mean, z_log_var])\n",
    "\n",
    "        encoder = Model(inputs, [z_mean, z_log_var, z], name ='encoder')\n",
    "\n",
    "        latent_input = Input(shape=(self.latent_dim,), name = 'z_sampling')\n",
    "        x = Dense(30, activation = 'relu', kernel_initializer= 'he_uniform')(latent_input)\n",
    "        x = Dense(32, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(64, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(128, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(64, activation = 'relu', kernel_initializer= 'he_uniform')(x)\n",
    "        x = Dense(orignal_dim, activation = None, kernel_initializer= None)(x)\n",
    "        \n",
    "        decoder = Model(latent_input, x, name ='decoder')\n",
    "        output = decoder(encoder(inputs)[2])\n",
    "\n",
    "        def vae_loss():\n",
    "            model_input = K.flatten(inputs)\n",
    "            model_output = K.flatten(output)\n",
    "\n",
    "            recon_loss= mse(model_input, model_output)\n",
    "            # recon_loss = binary_crossentropy(model_input, model_output)\n",
    "            # recon_loss *= self.input_shape[0]\n",
    "            kl_loss = -5e-4 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "            return K.mean(recon_loss + kl_loss)\n",
    "\n",
    "        vae = Model(inputs, output, name='vae')\n",
    "        vae.add_loss(vae_loss())\n",
    "\n",
    "        return vae, encoder, decoder\n",
    "    \n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        x_data = x_data.values\n",
    "        y_data = y_data.values\n",
    "        \n",
    "        input_shape = x_data.shape[1:]\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss', verbose=1, patience=30, mode='min', restore_best_weights=True)\n",
    "        \n",
    "        self.model, self.encoder, self.decoder = self._variational_autoencoder(input_shape)\n",
    "        \n",
    "        # adam = Adam(0.0001)\n",
    "        adadelta = tf.keras.optimizers.Adadelta(learning_rate=1., rho=0.95, epsilon=1e-07, name='Adadelta')\n",
    "        self.model.compile(optimizer=adadelta, loss=None)\n",
    "        self.model.fit(x= x_train, y= None,\n",
    "                       validation_data=(x_test, None),\n",
    "                       callbacks = [early_stopping], \n",
    "                       epochs=1000, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_anomaly(error_df, threshold = None):\n",
    "    \n",
    "    if threshold is None:\n",
    "        threshold = error_df[error_df['Class'] == 1].y_pred.quantile(q = 0.5) # 95 % higher\n",
    "        print('Generated threshold : {}'.format(threshold))\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "    for name, group in error_df.groupby('Class'):\n",
    "        ax.plot(group.index, group['y_pred'], marker = 'o', linestyle = '', alpha = 0.6, \n",
    "                label = \"Fraud\" if name == 1 else \"Normal\",\n",
    "                color = 'r' if name == 1 else 'royalblue')\n",
    "\n",
    "    ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], \n",
    "              colors = 'r', zorder = 100, label = 'Threshold')\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "def confusion_matrix_report(true, pred):\n",
    "    [tn, fp, fn, tp] = confusion_matrix(true, pred).ravel()\n",
    "    precision = tp/(fp + tp)\n",
    "    recall = tp/(fn + tp)\n",
    "    print(f\"\\t\\tT\\tF\")\n",
    "    print(f\"\\t1 [{tp:5d}, {fn:5d}]\")\n",
    "    print(f\"\\t0 [{fp:5d}, {tn:5d}]\")\n",
    "    print(f\"accuracy : \\t{ (tp+tn)/(tn + fp + fn + tp) :2.5f}\")\n",
    "    print(f\"precision : \\t{precision:2.5f}\")\n",
    "    print(f\"recall : \\t{recall:2.5f}\")\n",
    "    print(f\"f1score : \\t{(2*recall*precision)/(recall+precision):2.5f}\")\n",
    "    \n",
    "    \n",
    "def shuffle(x, y):\n",
    "    idx = list(range(y_resample.shape[0]))\n",
    "    random.shuffle(idx)\n",
    "    return x[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(\"/home/gruds/projects/chan/pico/dataset/credit_card\",\"preprocessed.csv\"), index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "           'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "           'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Time',\n",
    "           'Class']\n",
    "dataset = dataset[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalize:\n",
    "    is_fraud = dataset.Class.values.copy()\n",
    "\n",
    "    scaler = StandardScaler() # RobustScaler # MinMaxScaler # StandardScaler\n",
    "\n",
    "    transformed = dataset.drop(\"Class\",axis =1)\n",
    "    columns = transformed.columns\n",
    "    transformed = scaler.fit_transform(transformed)\n",
    "\n",
    "    del dataset\n",
    "    dataset = pd.DataFrame(data=transformed, columns=columns)\n",
    "    dataset = dataset.assign(Class = is_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop('Class', axis =1)\n",
    "y = dataset.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 227430, 1: 393})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_autoencoder = VariationalAutoencoder(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normal = x_train[y_train==0]\n",
    "y_normal = y_train[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "Train on 181944 samples, validate on 45486 samples\n",
      "Epoch 1/1000\n",
      "181944/181944 [==============================] - 14s 76us/sample - loss: 0.9673 - val_loss: 0.8404\n",
      "Epoch 2/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.7636 - val_loss: 0.6812\n",
      "Epoch 3/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.6213 - val_loss: 0.5696\n",
      "Epoch 4/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.5298 - val_loss: 0.4994\n",
      "Epoch 5/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.4569 - val_loss: 0.4455\n",
      "Epoch 6/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.4066 - val_loss: 0.3790\n",
      "Epoch 7/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.3642 - val_loss: 0.3516\n",
      "Epoch 8/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.3354 - val_loss: 0.3238\n",
      "Epoch 9/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.3146 - val_loss: 0.3001\n",
      "Epoch 10/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.3029 - val_loss: 0.2960\n",
      "Epoch 11/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2931 - val_loss: 0.2830\n",
      "Epoch 12/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2861 - val_loss: 0.2825\n",
      "Epoch 13/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2788 - val_loss: 0.2704\n",
      "Epoch 14/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2723 - val_loss: 0.2753\n",
      "Epoch 15/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2676 - val_loss: 0.2637\n",
      "Epoch 16/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2618 - val_loss: 0.2702\n",
      "Epoch 17/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2571 - val_loss: 0.2564\n",
      "Epoch 18/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2528 - val_loss: 0.2597\n",
      "Epoch 19/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2492 - val_loss: 0.2562\n",
      "Epoch 20/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2461 - val_loss: 0.2596\n",
      "Epoch 21/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2431 - val_loss: 0.2439\n",
      "Epoch 22/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2410 - val_loss: 0.2623\n",
      "Epoch 23/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2379 - val_loss: 0.2421\n",
      "Epoch 24/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2350 - val_loss: 0.2485\n",
      "Epoch 25/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2330 - val_loss: 0.2360\n",
      "Epoch 26/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2297 - val_loss: 0.2442\n",
      "Epoch 27/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.2278 - val_loss: 0.2394\n",
      "Epoch 28/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2254 - val_loss: 0.2334\n",
      "Epoch 29/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2227 - val_loss: 0.2325\n",
      "Epoch 30/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2211 - val_loss: 0.2346\n",
      "Epoch 31/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2195 - val_loss: 0.2267\n",
      "Epoch 32/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.2174 - val_loss: 0.2219\n",
      "Epoch 33/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2159 - val_loss: 0.2161\n",
      "Epoch 34/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2138 - val_loss: 0.2272\n",
      "Epoch 35/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2128 - val_loss: 0.2224\n",
      "Epoch 36/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2107 - val_loss: 0.2220\n",
      "Epoch 37/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2096 - val_loss: 0.2111\n",
      "Epoch 38/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.2075 - val_loss: 0.2127\n",
      "Epoch 39/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2068 - val_loss: 0.2076\n",
      "Epoch 40/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2050 - val_loss: 0.2151\n",
      "Epoch 41/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2035 - val_loss: 0.2314\n",
      "Epoch 42/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2023 - val_loss: 0.2305\n",
      "Epoch 43/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.2012 - val_loss: 0.2227\n",
      "Epoch 44/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.2000 - val_loss: 0.2120\n",
      "Epoch 45/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1988 - val_loss: 0.2017\n",
      "Epoch 46/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1975 - val_loss: 0.2033\n",
      "Epoch 47/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1964 - val_loss: 0.2004\n",
      "Epoch 48/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1961 - val_loss: 0.2430\n",
      "Epoch 49/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1946 - val_loss: 0.2398\n",
      "Epoch 50/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1939 - val_loss: 0.2022\n",
      "Epoch 51/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1929 - val_loss: 0.1976\n",
      "Epoch 52/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1919 - val_loss: 0.1963\n",
      "Epoch 53/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1913 - val_loss: 0.1969\n",
      "Epoch 54/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1906 - val_loss: 0.2016\n",
      "Epoch 55/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1899 - val_loss: 0.1942\n",
      "Epoch 56/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1888 - val_loss: 0.2034\n",
      "Epoch 57/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1884 - val_loss: 0.2091\n",
      "Epoch 58/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1879 - val_loss: 0.1963\n",
      "Epoch 59/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1865 - val_loss: 0.1851\n",
      "Epoch 60/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1858 - val_loss: 0.1933\n",
      "Epoch 61/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1859 - val_loss: 0.1975\n",
      "Epoch 62/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1848 - val_loss: 0.1851\n",
      "Epoch 63/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1837 - val_loss: 0.1934\n",
      "Epoch 64/1000\n",
      "181944/181944 [==============================] - 13s 69us/sample - loss: 0.1839 - val_loss: 0.2134\n",
      "Epoch 65/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1828 - val_loss: 0.1921\n",
      "Epoch 66/1000\n",
      "181944/181944 [==============================] - 13s 69us/sample - loss: 0.1825 - val_loss: 0.1849\n",
      "Epoch 67/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1820 - val_loss: 0.2147\n",
      "Epoch 68/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1811 - val_loss: 0.1897\n",
      "Epoch 69/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1810 - val_loss: 0.1978\n",
      "Epoch 70/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1800 - val_loss: 0.1873\n",
      "Epoch 71/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1801 - val_loss: 0.1783\n",
      "Epoch 72/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1797 - val_loss: 0.2018\n",
      "Epoch 73/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1788 - val_loss: 0.1793\n",
      "Epoch 74/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1784 - val_loss: 0.1870\n",
      "Epoch 75/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1778 - val_loss: 0.1934\n",
      "Epoch 76/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1773 - val_loss: 0.1911\n",
      "Epoch 77/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1767 - val_loss: 0.1847\n",
      "Epoch 78/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1766 - val_loss: 0.1854\n",
      "Epoch 79/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1765 - val_loss: 0.1849\n",
      "Epoch 80/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1757 - val_loss: 0.1856\n",
      "Epoch 81/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1755 - val_loss: 0.1860\n",
      "Epoch 82/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1748 - val_loss: 0.1861\n",
      "Epoch 83/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1747 - val_loss: 0.1841\n",
      "Epoch 84/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1744 - val_loss: 0.1943\n",
      "Epoch 85/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1740 - val_loss: 0.1985\n",
      "Epoch 86/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1737 - val_loss: 0.1914\n",
      "Epoch 87/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1734 - val_loss: 0.1795\n",
      "Epoch 88/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1728 - val_loss: 0.1745\n",
      "Epoch 89/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1733 - val_loss: 0.1730\n",
      "Epoch 90/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1722 - val_loss: 0.1803\n",
      "Epoch 91/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1717 - val_loss: 0.1733\n",
      "Epoch 92/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1717 - val_loss: 0.1885\n",
      "Epoch 93/1000\n",
      "181944/181944 [==============================] - 12s 69us/sample - loss: 0.1711 - val_loss: 0.1805\n",
      "Epoch 94/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1708 - val_loss: 0.1739\n",
      "Epoch 95/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1704 - val_loss: 0.1774\n",
      "Epoch 96/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1705 - val_loss: 0.1793\n",
      "Epoch 97/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1702 - val_loss: 0.1787\n",
      "Epoch 98/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1698 - val_loss: 0.1767\n",
      "Epoch 99/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1692 - val_loss: 0.1794\n",
      "Epoch 100/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1689 - val_loss: 0.1733\n",
      "Epoch 101/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1688 - val_loss: 0.1726\n",
      "Epoch 102/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1680 - val_loss: 0.1741\n",
      "Epoch 103/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1683 - val_loss: 0.1798\n",
      "Epoch 104/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1678 - val_loss: 0.1684\n",
      "Epoch 105/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1675 - val_loss: 0.1746\n",
      "Epoch 106/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1672 - val_loss: 0.1867\n",
      "Epoch 107/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1672 - val_loss: 0.1909\n",
      "Epoch 108/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1668 - val_loss: 0.1755\n",
      "Epoch 109/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1661 - val_loss: 0.1844\n",
      "Epoch 110/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1665 - val_loss: 0.1793\n",
      "Epoch 111/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1661 - val_loss: 0.1819\n",
      "Epoch 112/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1660 - val_loss: 0.1769\n",
      "Epoch 113/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1655 - val_loss: 0.1796\n",
      "Epoch 114/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1651 - val_loss: 0.1722\n",
      "Epoch 115/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1651 - val_loss: 0.1722\n",
      "Epoch 116/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1650 - val_loss: 0.1720\n",
      "Epoch 117/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1641 - val_loss: 0.1696\n",
      "Epoch 118/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1646 - val_loss: 0.1672\n",
      "Epoch 119/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1638 - val_loss: 0.1771\n",
      "Epoch 120/1000\n",
      "181944/181944 [==============================] - 12s 69us/sample - loss: 0.1637 - val_loss: 0.1715\n",
      "Epoch 121/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1639 - val_loss: 0.1734\n",
      "Epoch 122/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1634 - val_loss: 0.1788\n",
      "Epoch 123/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1634 - val_loss: 0.1687\n",
      "Epoch 124/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1629 - val_loss: 0.1712\n",
      "Epoch 125/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1628 - val_loss: 0.1702\n",
      "Epoch 126/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1624 - val_loss: 0.1660\n",
      "Epoch 127/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1618 - val_loss: 0.1697\n",
      "Epoch 128/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1623 - val_loss: 0.1884\n",
      "Epoch 129/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1616 - val_loss: 0.1787\n",
      "Epoch 130/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1617 - val_loss: 0.1835\n",
      "Epoch 131/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1615 - val_loss: 0.1729\n",
      "Epoch 132/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1612 - val_loss: 0.1673\n",
      "Epoch 133/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1613 - val_loss: 0.1696\n",
      "Epoch 134/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1610 - val_loss: 0.1672\n",
      "Epoch 135/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1611 - val_loss: 0.1692\n",
      "Epoch 136/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1605 - val_loss: 0.1678\n",
      "Epoch 137/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1609 - val_loss: 0.1650\n",
      "Epoch 138/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1605 - val_loss: 0.1771\n",
      "Epoch 139/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1598 - val_loss: 0.1707\n",
      "Epoch 140/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1597 - val_loss: 0.1623\n",
      "Epoch 141/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1598 - val_loss: 0.1684\n",
      "Epoch 142/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1599 - val_loss: 0.1646\n",
      "Epoch 143/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1598 - val_loss: 0.1666\n",
      "Epoch 144/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1591 - val_loss: 0.1721\n",
      "Epoch 145/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1590 - val_loss: 0.1716\n",
      "Epoch 146/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1586 - val_loss: 0.1692\n",
      "Epoch 147/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1585 - val_loss: 0.1653\n",
      "Epoch 148/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1584 - val_loss: 0.1638\n",
      "Epoch 149/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1585 - val_loss: 0.1740\n",
      "Epoch 150/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1583 - val_loss: 0.1790\n",
      "Epoch 151/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1579 - val_loss: 0.1629\n",
      "Epoch 152/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1581 - val_loss: 0.1631\n",
      "Epoch 153/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1576 - val_loss: 0.1914\n",
      "Epoch 154/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1571 - val_loss: 0.1714\n",
      "Epoch 155/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1571 - val_loss: 0.1615\n",
      "Epoch 156/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1570 - val_loss: 0.1694\n",
      "Epoch 157/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1564 - val_loss: 0.1699\n",
      "Epoch 158/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1570 - val_loss: 0.1826\n",
      "Epoch 159/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1567 - val_loss: 0.1646\n",
      "Epoch 160/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1568 - val_loss: 0.1687\n",
      "Epoch 161/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1562 - val_loss: 0.1638\n",
      "Epoch 162/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1560 - val_loss: 0.1660\n",
      "Epoch 163/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1565 - val_loss: 0.1573\n",
      "Epoch 164/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1559 - val_loss: 0.1593\n",
      "Epoch 165/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1555 - val_loss: 0.1633\n",
      "Epoch 166/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1556 - val_loss: 0.1613\n",
      "Epoch 167/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1556 - val_loss: 0.1682\n",
      "Epoch 168/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1552 - val_loss: 0.1626\n",
      "Epoch 169/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1554 - val_loss: 0.1724\n",
      "Epoch 170/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1555 - val_loss: 0.1611\n",
      "Epoch 171/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1548 - val_loss: 0.1603\n",
      "Epoch 172/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1553 - val_loss: 0.1638\n",
      "Epoch 173/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1547 - val_loss: 0.1683\n",
      "Epoch 174/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1554 - val_loss: 0.1621\n",
      "Epoch 175/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1551 - val_loss: 0.1565\n",
      "Epoch 176/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1552 - val_loss: 0.1627\n",
      "Epoch 177/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1553 - val_loss: 0.1585\n",
      "Epoch 178/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1543 - val_loss: 0.1615\n",
      "Epoch 179/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1548 - val_loss: 0.1782\n",
      "Epoch 180/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1545 - val_loss: 0.1687\n",
      "Epoch 181/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1544 - val_loss: 0.1622\n",
      "Epoch 182/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1542 - val_loss: 0.1739\n",
      "Epoch 183/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1541 - val_loss: 0.1570\n",
      "Epoch 184/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1538 - val_loss: 0.1698\n",
      "Epoch 185/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1535 - val_loss: 0.1635\n",
      "Epoch 186/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1535 - val_loss: 0.1701\n",
      "Epoch 187/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1537 - val_loss: 0.1635\n",
      "Epoch 188/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1545 - val_loss: 0.1741\n",
      "Epoch 189/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1538 - val_loss: 0.1672\n",
      "Epoch 190/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1536 - val_loss: 0.1573\n",
      "Epoch 191/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1532 - val_loss: 0.1713\n",
      "Epoch 192/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1539 - val_loss: 0.1687\n",
      "Epoch 193/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1541 - val_loss: 0.1583\n",
      "Epoch 194/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1534 - val_loss: 0.1620\n",
      "Epoch 195/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1533 - val_loss: 0.1677\n",
      "Epoch 196/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1532 - val_loss: 0.1728\n",
      "Epoch 197/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1528 - val_loss: 0.1670\n",
      "Epoch 198/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1521 - val_loss: 0.1713\n",
      "Epoch 199/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1517 - val_loss: 0.1616\n",
      "Epoch 200/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1519 - val_loss: 0.1625\n",
      "Epoch 201/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1518 - val_loss: 0.1621\n",
      "Epoch 202/1000\n",
      "181944/181944 [==============================] - 12s 69us/sample - loss: 0.1517 - val_loss: 0.1748\n",
      "Epoch 203/1000\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1514 - val_loss: 0.1600\n",
      "Epoch 204/1000\n",
      "181944/181944 [==============================] - 12s 67us/sample - loss: 0.1512 - val_loss: 0.1577\n",
      "Epoch 205/1000\n",
      "181248/181944 [============================>.] - ETA: 0s - loss: 0.1515Restoring model weights from the end of the best epoch.\n",
      "181944/181944 [==============================] - 12s 68us/sample - loss: 0.1515 - val_loss: 0.1595\n",
      "Epoch 00205: early stopping\n"
     ]
    }
   ],
   "source": [
    "variational_autoencoder.fit(x_normal, y_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "56956/56956 [==============================] - 5s 79us/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred = variational_autoencoder.model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_error = []\n",
    "for p,t in zip(y_pred, x_test.values.astype('float32')):\n",
    "    recon_error.append( np.mean((p-t)**2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame({\n",
    "                \"y_pred\" : recon_error,\n",
    "                \"Class\" : y_test,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tT\tF\n",
      "\t1 [   45,    50]\n",
      "\t0 [   91, 56770]\n",
      "accuracy : \t0.99752\n",
      "precision : \t0.33088\n",
      "recall : \t0.47368\n",
      "f1score : \t0.38961\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_report(error_df.Class, error_df.y_pred > 1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated threshold : 1.7908118963241577\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_anomaly(error_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pico",
   "language": "python",
   "name": "pico"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
